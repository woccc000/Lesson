from keras.models import Sequential
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dense
from keras.datasets import mnist
from keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt
from keras.utils import to_categorical

class LeNet:
    @staticmethod
    def build(input_shape, classes):
        model = Sequential()
        # CONV => RELU => POOL
        try:
            model.add(Conv2D(20, kernel_size=5,
                             padding='same',
                             input_shape=input_shape))
            model.add(Activation('relu'))
            model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

            model.add(Conv2D(filters=50, kernel_size=5, padding='same'))
            model.add(Activation('relu'))
            model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

            # Слои Flatten => RELU
            model.add(Flatten())
            model.add(Activation('relu'))

            # softmax - классификатор
            model.add(Dense(classes))
            model.add(Activation("softmax"))
            return model
        except Exception as exc:
            print(f"Ошибка возникла в блоке кода 1 {LeNet()}: {exc}")


# Сеть и обучение
NB_EPOCHS = 20
BATCH_SIZE = 128
VERBOSE = 1
OPTIMIZER = Adam()
VALIDATION_SPLIT = 0.2
#IMG_ROWS, IMG_COLS = 28, 28 # Размер Входного изображения
NB_CLASSES = 10 # Число выходов = число цифр
INPUT_SHAPE = (1, 28, 28, 1)

# Загрузка данных MNIST
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Преобразование данных в форму (None, 28, 28, 1)
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
input_shape = (1, 28, 28, 20)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

# Нам нужна форма 60к * [1 x 28 x 28], подаваемая на вход
# светочной сет
x_train = x_train[:, np.newaxis, :, :]
x_test = x_test[:, np.newaxis, :, :]
print(x_train.shape[0], 'train sample')
print(x_test.shape[0], 'test sample')

# Преобразуем векторы класоов в бинарные матрицы классовy
y_train = to_categorical(y_train, num_classes=10)
y_test = to_categorical(y_test, num_classes=10)

try:
    # Инициализация оптимизатор и модель
    model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)
    model.compile(loss='categorical_crossentropy',
                  metrics=["accuracy"])
    history = model.fit(x_train, y_train,
                        batch_size=BATCH_SIZE,
                        epochs=NB_EPOCHS,
                        verbose=VERBOSE,
                        validation_split=VALIDATION_SPLIT)
    score = model.evaluate(x_test, y_test, verbose=VERBOSE)
    print("Test score: ", score[0])
    print("Test accuracy: ", score[1])

    # Перечислим все данные в истории
    print(history.history.keys())
    globals(history)
except Exception as exc:
    print(f"Ошибка возникла в блоке кода 2: {exc}")

try:
    # Построить график изменения верности
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_acc'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()

    # ПОстоить график изменения потери
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()
except Exception as exc:
    print(f"Ошибка возникла в блоке 3: {exc}")
